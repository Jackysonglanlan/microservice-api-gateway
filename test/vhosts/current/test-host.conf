#

upstream test_backends {
  server localhost:7778;

  # 在任何时候保持最少 64 个HTTP/ 1.1连接到代理服务器, 如果有更多的流量, nginx 将打开更多的连接
  keepalive 64;
}

server {
  # SO_REUSEPORT选项启用后，存在对每一个IP地址和端口绑定连接的多个socket监听器，每一个工作进程都可以分配一个。
  # 系统内核决定哪一个有效的socket监听器（通过隐式的方式，给哪一个工作进程）获得连接。
  # 这可以减少工作进程之间获得新连接时的封锁竞争（译者注：工作进程请求获得互斥资源加锁之间的竞争），同时在多核系统可以提高性能。
  # 然而，这也意味着当一个工作进程陷入阻塞操作时，阻塞影响的不仅是已经接受连接的工作进程，也同时让内核发送连接请求计划分配的工作进程
  # 因此变为阻塞。

  # 引用reuseport参数后，对引用的socket，accept_mutex参数将会无效，因为互斥量（mutex）对reuseport来说是多余的。
  # 对没有使用reuseport的端口，设置accept_mutex仍然是有价值的。
  listen *:7777 reuseport;

  default_type application/json;

  resolver 8.8.8.8; # used when we send http request over cosocket

  location = /demo-lua-json {
    content_by_lua_block {
      ngx.say(JSON.encode({type = "embed", msg = "hahahhhh"}))
    }
  }

  location ~ ^/lua-demo/(.+) {
    content_by_lua_file lua-demo/$1.lua;
  }

  location ~ ^/cache-test/.+ {
    # 启用线程池，如果要读取静态文件，不会导致 nginx 堵塞
    #
    # 但是，要不要启用?
    #
    # 实际上，最幸运的情况是，读取和发送文件操作不去处理缓慢的硬盘驱动器。如果我们有足够多的内存来存储数据集，
    # 那么操作系统将会足够聪明地在被称作“页面缓存”的地方，缓存频繁使用的文件。
    #
    # “页面缓存”的效果很好，可以让NGINX在几乎所有常见的用例中展示优异的性能。从页面缓存中读取比较快，没有人会说这种操作是“阻塞”。
    # 而另一方面，卸载任务到一个线程池是有一定开销的。
    #
    # 因此，如果内存有合理的大小并且待处理的数据集不是很大的话，那么无需使用线程池，NGINX已经工作在最优化的方式下。
    #
    # 卸载读操作到线程池是一种适用于非常特殊任务的技术。只有当经常请求的内容的大小，不适合操作系统的虚拟机缓存时，这种技术才是最有用的。
    # 至于可能适用的场景，比如，基于NGINX的高负载流媒体服务器
    #
    # 见 https://linux.cn/article-5684-1.html
    #
    # WARN: mac 上不支持这个指令
    # aio threads;

    # 启用 auto-cache
    #
    # 为什么不用 nginx 自带的 proxy_cache, 非要自己写?
    #
    # 1. 无法自定义 缓存的 存储/读取/是否启用 机制 (实际需求中，不是每个接口的数据都需要缓存，或者能够缓存)
    # 2. proxy_cache 是基于磁盘的，会带来阻塞 (虽然相比转发到后端服务器，已经很快了)
    # 3. 无扩展性，不能根据业务定制
    access_by_lua_block{
      local autoCache = require('server.filters.auto-cache.auto-cache')
      autoCache.applyAutoCache(ngx)
    }

    proxy_pass            http://test_backends;

    header_filter_by_lua_block{
      local autoCacheHeadHandler = require('server.filters.auto-cache.auto-cache-trigger')
      autoCacheHeadHandler.detectBackendCacheRequest(ngx)
    }

    body_filter_by_lua_block{
      local autoCacheMaker = require('server.filters.auto-cache.auto-cache-maker')
      autoCacheMaker.makeCache(ngx)
    }
  }

  location = /api-sign-check {
    # 拦截请求
    access_by_lua_block{
      local apiSignChecker = require('server.filters.api-sign-checker')
      apiSignChecker.checkAPISign()
    }

    proxy_pass            http://test_backends;
  }

  location ~ ^/api/([^/]+)/?(.*) {
    content_by_lua_block{
      local router = require('server.router')
      router.dispatch('/api', ngx.var[1], ngx.var[2]) -- 等价于 $1 $2
    }
  }

  location / {
    default_type application/json;
    return 200 '{"error":"not allowed","code":600}';
  }

  # if ($http_user_agent ~* (wget|curl) ) {
  #   return 200 '{"error":"not allowed","code":600}';
  # }

  # -------------
  # nginx 不支持 if 逻辑 与或 运算，而且不支持 if 嵌套，可以通过下面的方法来模拟:
  #
  # set $flag 0;
  # if ($uri ~ ^/thumb/[0-9]+_160.jpg$){
  #  set $flag "${flag}1";
  # }
  # if ($arg_unitid = 42012){
  #  set $flag "${flag}1";
  # }
  # if ($flag = "011"){
  #  echo "www.ttlsa.com";
  # }

}
